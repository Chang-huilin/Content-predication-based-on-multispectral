{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch# type: ignore\n",
    "import torch.nn as nn# type: ignore\n",
    "import torch.nn.functional as F# type: ignore\n",
    "import torch.optim as optim# type: ignore\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import matplotlib.pyplot as plt\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入数据\n",
    "file_path = r\"D:\\红茶数据2024.0423\\多光谱\\萎凋过程-多光谱\\结果\\自然萎凋\\FAAs.mat\"\n",
    "data = sio.loadmat(file_path)\n",
    "# 提取X和Y\n",
    "X = data['X']\n",
    "Y = data['Y'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# K折交叉验证\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    Y_train, Y_test = Y[train_index], Y[test_index]\n",
    "\n",
    "    # 数据归一化\n",
    "    scaler_X = MinMaxScaler()\n",
    "    scaler_Y = MinMaxScaler()\n",
    "\n",
    "    X_train = scaler_X.fit_transform(X_train)\n",
    "    X_test = scaler_X.transform(X_test)\n",
    "\n",
    "    Y_train = scaler_Y.fit_transform(Y_train.reshape(-1, 1)).flatten()\n",
    "    Y_test = scaler_Y.transform(Y_test.reshape(-1, 1)).flatten()\n",
    "\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 转换为 PyTorch 张量\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32).unsqueeze(1).unsqueeze(1)  # 增加维度适应Conv2d\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32).unsqueeze(1).unsqueeze(1)\n",
    "Y_train_tensor = torch.tensor(Y_train, dtype=torch.float32)\n",
    "Y_test_tensor = torch.tensor(Y_test, dtype=torch.float32)\n",
    "\n",
    "# Squeeze-and-Excitation Block\n",
    "class SEBlock(nn.Module):\n",
    "    def __init__(self, in_channels, reduction=16):\n",
    "        super(SEBlock, self).__init__()\n",
    "        self.fc1 = nn.Linear(in_channels, in_channels // reduction, bias=False)\n",
    "        self.fc2 = nn.Linear(in_channels // reduction, in_channels, bias=False)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, _, _ = x.size()\n",
    "        y = torch.mean(x, dim=(2, 3), keepdim=False)  # Global Average Pooling\n",
    "        y = self.fc1(y)\n",
    "        y = F.relu(y)\n",
    "        y = self.fc2(y)\n",
    "        y = self.sigmoid(y).view(b, c, 1, 1)\n",
    "        return x * y  # Apply SE weights to the input\n",
    "\n",
    "# Bottleneck Block with SE\n",
    "class SEBottleneck(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1, downsample=None, reduction=16):\n",
    "        super(SEBottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv3 = nn.Conv2d(out_channels, out_channels * 4, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(out_channels * 4)\n",
    "        self.se = SEBlock(out_channels * 4, reduction)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(x)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        # Apply SE Block\n",
    "        out = self.se(out)\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, (3, 1), padding=(1, 0))  # First convolution\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.pool = nn.MaxPool2d((1, 1))  # Pooling layer\n",
    "\n",
    "        self.conv2 = nn.Conv2d(16, 32, (3, 1), padding=(1, 0))  # Second convolution\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "\n",
    "        self.se = SEBlock(32)  # SE block after second convolution\n",
    "\n",
    "        self.fc = nn.Linear(32 * X_train.shape[1], 1)  # Adjust input size for the fully connected layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.se(x)  # Apply SE block\n",
    "\n",
    "        x = torch.flatten(x, start_dim=1)  # Flatten for the fully connected layer\n",
    "        x = self.fc(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/1500], Loss: 0.0262, LR: 0.001000\n",
      "Epoch [200/1500], Loss: 0.0204, LR: 0.001000\n",
      "Epoch [300/1500], Loss: 0.0157, LR: 0.001000\n",
      "Epoch [400/1500], Loss: 0.0117, LR: 0.001000\n",
      "Epoch [500/1500], Loss: 0.0083, LR: 0.000100\n",
      "Epoch [600/1500], Loss: 0.0080, LR: 0.000100\n",
      "Epoch [700/1500], Loss: 0.0078, LR: 0.000100\n",
      "Epoch [800/1500], Loss: 0.0076, LR: 0.000100\n",
      "Epoch [900/1500], Loss: 0.0073, LR: 0.000100\n",
      "Epoch [1000/1500], Loss: 0.0071, LR: 0.000010\n",
      "Epoch [1100/1500], Loss: 0.0070, LR: 0.000010\n",
      "Epoch [1200/1500], Loss: 0.0070, LR: 0.000010\n",
      "Epoch [1300/1500], Loss: 0.0070, LR: 0.000010\n",
      "Epoch [1400/1500], Loss: 0.0070, LR: 0.000010\n",
      "Epoch [1500/1500], Loss: 0.0069, LR: 0.000001\n",
      "Test Loss: 0.0671\n"
     ]
    }
   ],
   "source": [
    "# 初始化模型\n",
    "model = ConvNet()\n",
    "\n",
    "\n",
    "# 损失函数和优化器\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)  # Adam 优化器\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=500, gamma=0.1)  # 学习率调度器\n",
    "\n",
    "# 训练模型\n",
    "num_epochs = 1500\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    \n",
    "    # 前向传播\n",
    "    outputs = model(X_train_tensor)\n",
    "    loss = criterion(outputs.flatten(), Y_train_tensor)\n",
    "    \n",
    "    # 反向传播和优化\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "\n",
    "    # 打印日志\n",
    "    if (epoch + 1) % 100 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}, LR: {optimizer.param_groups[0][\"lr\"]:.6f}')\n",
    "\n",
    "# 测试模型\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    predictions = model(X_test_tensor)\n",
    "    test_loss = criterion(predictions.flatten(), Y_test_tensor)\n",
    "    print(f'Test Loss: {test_loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在训练完成后保存模型\n",
    "torch.save(model.state_dict(), 'trained_attention.pth')  # 保存模型的参数\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvNet(\n",
       "  (conv1): Conv2d(1, 16, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))\n",
       "  (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU()\n",
       "  (pool): MaxPool2d(kernel_size=(1, 1), stride=(1, 1), padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(16, 32, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))\n",
       "  (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (se): SEBlock(\n",
       "    (fc1): Linear(in_features=32, out_features=2, bias=False)\n",
       "    (fc2): Linear(in_features=2, out_features=32, bias=False)\n",
       "    (sigmoid): Sigmoid()\n",
       "  )\n",
       "  (fc): Linear(in_features=1504, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 创建一个新的模型实例\n",
    "model = ConvNet()\n",
    "\n",
    "# 加载保存的模型参数\n",
    "model.load_state_dict(torch.load('trained_attention.pth'))\n",
    "\n",
    "# 将模型设置为评估模式\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型预测\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    Y_train_pred = model(X_train_tensor).flatten()\n",
    "    Y_test_pred = model(X_test_tensor).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training RMSE: 0.270\n",
      "Test RMSE: 0.839\n",
      "Training R²: 0.8507\n",
      "Test R²: -0.2168\n",
      "Training Rc: 0.9223\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "math domain error",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 27\u001b[0m\n\u001b[0;32m     25\u001b[0m Rc \u001b[38;5;241m=\u001b[39m math\u001b[38;5;241m.\u001b[39msqrt(train_r2)\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining Rc: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mRc\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 27\u001b[0m Rp \u001b[38;5;241m=\u001b[39m \u001b[43mmath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_r2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTesting Rp: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mRp\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# Plotting the prediction results\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: math domain error"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 设置字体为支持中文的字体，例如 SimHei\n",
    "plt.rcParams['font.family'] = 'SimHei'\n",
    "plt.rcParams['axes.unicode_minus'] = False  # 解决负号显示问题\n",
    "\n",
    "# Data inverse normalization\n",
    "Y_train_pred = scaler_Y.inverse_transform(Y_train_pred.numpy().reshape(-1, 1)).flatten()\n",
    "Y_test_pred = scaler_Y.inverse_transform(Y_test_pred.numpy().reshape(-1, 1)).flatten()\n",
    "Y_train_actual = scaler_Y.inverse_transform(Y_train_tensor.numpy().reshape(-1, 1)).flatten()\n",
    "Y_test_actual = scaler_Y.inverse_transform(Y_test_tensor.numpy().reshape(-1, 1)).flatten()\n",
    "\n",
    "# Root Mean Squared Error (RMSE)\n",
    "train_rmse = np.sqrt(mean_squared_error(Y_train_actual, Y_train_pred))\n",
    "test_rmse = np.sqrt(mean_squared_error(Y_test_actual, Y_test_pred))\n",
    "\n",
    "print(f'Training RMSE: {train_rmse:.3f}')\n",
    "print(f'Test RMSE: {test_rmse:.3f}')\n",
    "# R² coefficient calculation\n",
    "train_r2 = 1 - np.sum((Y_train_actual - Y_train_pred) ** 2) / np.sum((Y_train_actual - np.mean(Y_train_actual)) ** 2)\n",
    "test_r2 = 1 - np.sum((Y_test_actual - Y_test_pred) ** 2) / np.sum((Y_test_actual - np.mean(Y_test_actual)) ** 2)\n",
    "\n",
    "print(f'Training R²: {train_r2:.4f}')\n",
    "print(f'Test R²: {test_r2:.4f}')\n",
    "Rc = math.sqrt(train_r2)\n",
    "print(f'Training Rc: {Rc:.4f}')\n",
    "Rp = math.sqrt(test_r2)\n",
    "print(f'Testing Rp: {Rp:.4f}')\n",
    "# Plotting the prediction results\n",
    "plt.figure()\n",
    "plt.plot(Y_train_actual, 'r-*', label='Actual values')\n",
    "plt.plot(Y_train_pred, 'b-o', label='Predicted values')\n",
    "plt.title(f'Training Set Prediction Comparison (RMSE = {train_rmse:.4f})')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(Y_test_actual, 'r-*', label='Actual values')\n",
    "plt.plot(Y_test_pred, 'b-o', label='Predicted values')\n",
    "plt.title(f'Testing Set Prediction Comparison (RMSE = {test_rmse:.4f})')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# MAE and MBE calculation\n",
    "train_mae = mean_absolute_error(Y_train_actual, Y_train_pred)\n",
    "test_mae = mean_absolute_error(Y_test_actual, Y_test_pred)\n",
    "\n",
    "train_mbe = np.mean(Y_train_pred - Y_train_actual)\n",
    "test_mbe = np.mean(Y_test_pred - Y_test_actual)\n",
    "\n",
    "print(f'Training MAE: {train_mae:.4f}')\n",
    "print(f'Test MAE: {test_mae:.4f}')\n",
    "print(f'Training MBE: {train_mbe:.4f}')\n",
    "print(f'Test MBE: {test_mbe:.4f}')\n",
    "\n",
    "# 计算基准数据（实际观测数据）的标准差\n",
    "sd_reference_train = np.std(Y_train_actual)\n",
    "sd_reference_test = np.std(Y_test_actual)\n",
    "\n",
    "# 计算 RPD\n",
    "rpd_train = sd_reference_train / train_rmse  # 使用训练集的 RMSE\n",
    "rpd_test = sd_reference_test / test_rmse    # 使用测试集的 RMSE\n",
    "\n",
    "# 显示结果\n",
    "print(f'训练集数据的 RPD 为：{rpd_train:.4f}')\n",
    "print(f'测试集数据的 RPD 为：{rpd_test:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# 调整字体\n",
    "plt.rcParams['font.size'] = 24  # 设置全局字体大小\n",
    "plt.rcParams['font.family'] = 'Times New Roman'\n",
    "plt.rcParams['axes.unicode_minus'] = False  # 解决负号显示问题\n",
    "# 生成散点图比较真实值和预测值\n",
    "plt.figure(figsize=(8, 6)) #尺寸  \n",
    "plt.rcParams['lines.linewidth'] = 3  # 设置全局线宽\n",
    "# 绘制训练集散点图\n",
    "plt.scatter(Y_train_actual, Y_train_pred, c='blue', label='Training set', alpha=0.8, s=100)\n",
    "plt.scatter(Y_test_actual, Y_test_pred, c='orange', label='Testing set', alpha=0.8, s=100)\n",
    "\n",
    "# 绘制 y=x 参考线\n",
    "max_val = max(Y_train_actual.max(), Y_test_actual.max())\n",
    "min_val = min(Y_train_actual.min(), Y_test_actual.min())\n",
    "plt.plot([min_val, max_val], [min_val, max_val], 'r--', label='Ideal fit (y=x)')\n",
    "\n",
    "# 设置图形标题和标签\n",
    "plt.title('Actual vs Predicted Values', fontweight='bold')\n",
    "plt.xlabel('Actual Values', fontweight='bold')\n",
    "plt.ylabel('Predicted Values', fontweight='bold')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "42",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
